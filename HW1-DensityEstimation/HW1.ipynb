{
 "metadata": {
  "name": "",
  "signature": "sha256:35bd3e98de8a79f481d264f39ba24b65336427e3c6b1d4451a3ffb7d0cd2c2cd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.stats import multivariate_normal\n",
      "\n",
      "s = pd.Series([2, 4, 5.0, np.nan, 6, 8])\n",
      "print(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0    2.0\n",
        "1    4.0\n",
        "2    5.0\n",
        "3    NaN\n",
        "4    6.0\n",
        "5    8.0\n",
        "dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dates = pd.date_range('20161011', periods = 10)\n",
      "dates"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "DatetimeIndex(['2016-10-11', '2016-10-12', '2016-10-13', '2016-10-14',\n",
        "               '2016-10-15', '2016-10-16', '2016-10-17', '2016-10-18',\n",
        "               '2016-10-19', '2016-10-20'],\n",
        "              dtype='datetime64[ns]', freq='D')"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.DataFrame(np.random.randn(10,4), index = dates, columns = list('ABCD'))\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>A</th>\n",
        "      <th>B</th>\n",
        "      <th>C</th>\n",
        "      <th>D</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2016-10-11</th>\n",
        "      <td>0.794627</td>\n",
        "      <td>-1.721992</td>\n",
        "      <td>0.071271</td>\n",
        "      <td>-0.461080</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2016-10-12</th>\n",
        "      <td>1.609687</td>\n",
        "      <td>-0.171223</td>\n",
        "      <td>0.439767</td>\n",
        "      <td>-0.494049</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2016-10-13</th>\n",
        "      <td>-0.462856</td>\n",
        "      <td>-0.583103</td>\n",
        "      <td>-1.043301</td>\n",
        "      <td>0.748509</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2016-10-14</th>\n",
        "      <td>-0.446090</td>\n",
        "      <td>-0.754365</td>\n",
        "      <td>-0.280747</td>\n",
        "      <td>-0.813581</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2016-10-15</th>\n",
        "      <td>0.362964</td>\n",
        "      <td>-0.823261</td>\n",
        "      <td>-0.810160</td>\n",
        "      <td>0.179669</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2016-10-16</th>\n",
        "      <td>0.814988</td>\n",
        "      <td>-1.136141</td>\n",
        "      <td>-1.205174</td>\n",
        "      <td>-0.448391</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2016-10-17</th>\n",
        "      <td>-0.713295</td>\n",
        "      <td>0.305424</td>\n",
        "      <td>1.566869</td>\n",
        "      <td>0.213630</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2016-10-18</th>\n",
        "      <td>-0.804396</td>\n",
        "      <td>-0.717812</td>\n",
        "      <td>-1.440198</td>\n",
        "      <td>-0.450163</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2016-10-19</th>\n",
        "      <td>-0.263865</td>\n",
        "      <td>-0.634478</td>\n",
        "      <td>0.986669</td>\n",
        "      <td>1.041526</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2016-10-20</th>\n",
        "      <td>-1.544377</td>\n",
        "      <td>0.105228</td>\n",
        "      <td>-2.556445</td>\n",
        "      <td>0.858483</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "                   A         B         C         D\n",
        "2016-10-11  0.794627 -1.721992  0.071271 -0.461080\n",
        "2016-10-12  1.609687 -0.171223  0.439767 -0.494049\n",
        "2016-10-13 -0.462856 -0.583103 -1.043301  0.748509\n",
        "2016-10-14 -0.446090 -0.754365 -0.280747 -0.813581\n",
        "2016-10-15  0.362964 -0.823261 -0.810160  0.179669\n",
        "2016-10-16  0.814988 -1.136141 -1.205174 -0.448391\n",
        "2016-10-17 -0.713295  0.305424  1.566869  0.213630\n",
        "2016-10-18 -0.804396 -0.717812 -1.440198 -0.450163\n",
        "2016-10-19 -0.263865 -0.634478  0.986669  1.041526\n",
        "2016-10-20 -1.544377  0.105228 -2.556445  0.858483"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Iris is a popular garden flower which has a wide variety of colors among several species. \n",
      "Mr. Fisher (1936) has collected the data of three typical species of Iris: Iris setosa, Iris virginica and Iris versicolor.\n",
      "The goal of this project is to classify the Iris data using parametric and nonparametric methods. \n",
      "Each data set consists of 50 samples from each of three species. Four features were measured from each sample: sepal length, sepal width, petal length, petal width.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Iris classification using maximum likelihood with Gaussian assumption\n",
      "#Cross-validation\n",
      "#  To classify the data set, firstly we use 5-fold cross validation method to \n",
      "#  divide each data set into two parts. In details, with each 50 samples of each class,\n",
      "#  we use 40 samples for training and 10 samples for testing. We will repeat this process 5 times\n",
      "#  with different training set and testing set.\n",
      "dataIris = pd.read_table('iris.dat', delim_whitespace = True, header = None)\n",
      "dataIris.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>51</td>\n",
        "      <td>35</td>\n",
        "      <td>14</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>49</td>\n",
        "      <td>30</td>\n",
        "      <td>14</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>47</td>\n",
        "      <td>32</td>\n",
        "      <td>13</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>46</td>\n",
        "      <td>31</td>\n",
        "      <td>15</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>50</td>\n",
        "      <td>36</td>\n",
        "      <td>14</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "    0   1   2  3  4\n",
        "0  51  35  14  2  1\n",
        "1  49  30  14  2  1\n",
        "2  47  32  13  2  1\n",
        "3  46  31  15  2  1\n",
        "4  50  36  14  2  1"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arrayIrisData = dataIris.as_matrix()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sepal length & width, petal length & width  X - shape - 1*4   - dataframe 150*4- 50samples/ type \n",
      "# 5-fold cross validation\n",
      "# 1-fold -testing\n",
      "# (n-1) fold - training \n",
      "\n",
      "\n",
      "irisSetosa = arrayIrisData[0:50, 0:4]\n",
      "irisVerisColor = arrayIrisData[50:100, 0:4]\n",
      "irisVirginica  = arrayIrisData[100:150, 0:4]\n",
      "\n",
      "train_mats1 = [irisSetosa[10:50,:], irisVerisColor[10:50,:], irisVirginica[10:50,:]]\n",
      "test_mats1  = [irisSetosa[0:10,:],  irisVerisColor[0:10,:], irisVirginica[0:10,:]]\n",
      "\n",
      "train_mats2 = [np.concatenate((irisSetosa[0:10, :], irisSetosa[20:50,:]), axis = 0), \n",
      "               np.concatenate((irisVerisColor[0:10,:], irisVerisColor[20:50,:]), axis = 0), \n",
      "               np.concatenate((irisVirginica[0:10,:], irisVirginica[20:50,:]), axis = 0)]\n",
      "test_mats2  = [irisSetosa[10:20,:], irisVerisColor[10:20,:], irisVirginica[10:20,:]]\n",
      "\n",
      "train_mats3 = [np.concatenate((irisSetosa[0:20, :], irisSetosa[30:50,:]), axis = 0), \n",
      "               np.concatenate((irisVerisColor[0:20,:], irisVerisColor[30:50,:]), axis = 0), \n",
      "               np.concatenate((irisVirginica[0:20,:], irisVirginica[30:50,:]), axis = 0)]\n",
      "test_mats3  = [irisSetosa[20:30,:], irisVerisColor[20:30,:], irisVirginica[20:30,:]]\n",
      "\n",
      "train_mats4 = [np.concatenate((irisSetosa[0:30, :], irisSetosa[40:50,:]), axis = 0), \n",
      "               np.concatenate((irisVerisColor[0:30,:], irisVerisColor[40:50,:]), axis = 0), \n",
      "               np.concatenate((irisVirginica[0:30,:], irisVirginica[40:50,:]), axis = 0)]\n",
      "test_mats4  = [irisSetosa[30:40,:], irisVerisColor[30:40,:], irisVirginica[30:40,:]]\n",
      "\n",
      "train_mats5 = [irisSetosa[0:40,:], irisVerisColor[0:40,:], irisVirginica[0:40,:]]\n",
      "test_mats5  = [irisSetosa[40:50,:], irisVerisColor[40:50,:],irisVirginica[40:50,:]]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#train_mats\n",
      "train_mats = [train_mats1, train_mats2, train_mats3, train_mats4, train_mats5]\n",
      "test_mats  = [test_mats1, test_mats2, test_mats3, test_mats4, test_mats5]\n",
      "\n",
      "irisSetosa.shape\n",
      "train_mats1[0].shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "(40, 4)"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Gaussian assumption for Iris Data\n",
      "def classify_question1(trainData, testData):\n",
      "    u1 = np.mean(trainData[0], axis = 0)\n",
      "    c1 = np.cov(trainData[0].T)\n",
      "    u2 = np.mean(trainData[1], axis = 0)\n",
      "    c2 = np.cov(trainData[1].T)\n",
      "    u3 = np.mean(trainData[2], axis = 0)\n",
      "    c3 = np.cov(trainData[2].T)\n",
      "    for i in range(3):\n",
      "        test = testData[i]\n",
      "        c = [0, 0, 0]\n",
      "        for x in range(10):\n",
      "            p1 = multivariate_normal.pdf(test[x,:], u1,c1)\n",
      "            p2 = multivariate_normal.pdf(test[x,:], u2,c2)\n",
      "            p3 = multivariate_normal.pdf(test[x,:], u3,c3)\n",
      "            parray = np.array([p1, p2, p3])\n",
      "            c[np.argmax(parray)] += 1;\n",
      "        print(c)\n",
      "        \n",
      "def question1(train, test):\n",
      "    print(\"Confusion matrix\")\n",
      "    C1 = classify_question1(train[0], test[0])\n",
      "    print(\"----------------------------------\")\n",
      "    C2 = classify_question1(train[1], test[1])\n",
      "    print(\"----------------------------------\")\n",
      "    C3 = classify_question1(train[2], test[2])\n",
      "    print(\"----------------------------------\")\n",
      "    C4 = classify_question1(train[3], test[3])\n",
      "    print(\"----------------------------------\")\n",
      "    C5 = classify_question1(train[4], test[4])\n",
      "    \n",
      "question1(train_mats, test_mats)\n",
      "\n",
      "#Accuracy = 98%"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Confusion matrix\n",
        "[10, 0, 0]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0, 10, 0]\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "[10, 0, 0]\n",
        "[0, 10, 0]\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "[10, 0, 0]\n",
        "[0, 9, 1]\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "[10, 0, 0]\n",
        "[0, 9, 1]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0, 1, 9]\n",
        "----------------------------------\n",
        "[10, 0, 0]\n",
        "[0, 10, 0]\n",
        "[0, 0, 10]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Problem 2: Solving the iris classification problem using non-parametric method - kernel density estimation (KDE)\n",
      "# the hyperparameter - h- is determined by cross-validation method \n",
      "# we choose Gaussian kernel to estimate the density to prevent discontinuities (boundaries of cube). Therefore, we can obtain smoother\n",
      "# density model  \n",
      "import math\n",
      "\n",
      "\n",
      "#Naive approach - using loop to estimate distance in the kernel\n",
      "def get_prob_2_Naive(trainData, testData, h):\n",
      "    p = 0.0\n",
      "    for i in range(40):\n",
      "        distance = np.linalg.norm(testData-trainData[i,:])\n",
      "        p = p + 1.0/(np.sqrt(2*math.pi)*h*np.exp((distance*distance)*0.5/(h*h)))\n",
      "    p = p/40.0\n",
      "    return p\n",
      "\n",
      "def classify_question_2(trainMats, testMats, h):\n",
      "    for i in range(3):\n",
      "        test = testMats[i]\n",
      "        c = [0, 0, 0]\n",
      "        for j in range(10):\n",
      "            p1 = get_prob_2_Naive(trainMats[0], test[j, :], h)\n",
      "            p2 = get_prob_2_Naive(trainMats[1], test[j, :], h)\n",
      "            p3 = get_prob_2_Naive(trainMats[2], test[j, :], h)\n",
      "            parray = np.array([p1,p2, p3])\n",
      "            c[np.argmax(parray)] += 1\n",
      "        print(c)\n",
      "\n",
      "def question2(train, test, h):\n",
      "    print(\"Confusion matrix\")\n",
      "    C1 = classify_question_2(train[0], test[0], h)\n",
      "    print(\"----------------------------------\")\n",
      "    C2 = classify_question_2(train[1], test[1], h)\n",
      "    print(\"----------------------------------\")\n",
      "    C3 = classify_question_2(train[2], test[2], h)\n",
      "    print(\"----------------------------------\")\n",
      "    C4 = classify_question_2(train[3], test[3], h)\n",
      "    print(\"----------------------------------\")\n",
      "    C5 = classify_question_2(train[4], test[4], h)\n",
      "\n",
      "h = 0.5\n",
      "question2(train_mats, test_mats, h)\n",
      "\n",
      "irisSetosa.astype('float')\n",
      "irisVerisColor.astype('float')\n",
      "irisVirginica.astype('float')\n",
      "\n",
      "irisSetosa_New = np.ndarray(shape = irisSetosa.shape, dtype = float)\n",
      "irisVerisColor_New = np.ndarray(shape = irisVerisColor.shape, dtype = float)\n",
      "irisVirginica_New = np.ndarray(shape = irisVirginica.shape, dtype = float)\n",
      "\n",
      "#normalizing dataset to range [-1 1] by seeking the maximum and the minimum samples\n",
      "for c in range(4):\n",
      "    maxSetosa_c = np.amax(irisSetosa[:, c])\n",
      "    minSetosa_c = np.amin(irisSetosa[:, c])\n",
      "    d_Setosa = maxSetosa_c - minSetosa_c\n",
      "    print(d_Setosa)\n",
      "  \n",
      "    \n",
      "    maxVerisColor_c = np.amax(irisVerisColor[:, c])\n",
      "    minVerisColor_c = np.amin(irisVerisColor[:, c])\n",
      "    d_VerisColor = maxVerisColor_c - minVerisColor_c\n",
      "\n",
      "    \n",
      "    maxVir_c = np.amax(irisVirginica[:,c])\n",
      "    minVir_c = np.amin(irisVirginica[:,c])\n",
      "    d_Vir = maxVir_c - minVir_c\n",
      "    \n",
      "    #print(\"Setosa: \",  irisSetosa[0,0], \"minSetosa: \", minSetosa_c, \"difference: \", (irisSetosa[0,c] - minSetosa_c)/d_Setosa*2.0 - 1.0)\n",
      "    for r in range(50):\n",
      "        irisSetosa_New[r, c] = (irisSetosa[r, c] - minSetosa_c)*2.0 /d_Setosa-1.0\n",
      "        irisVerisColor_New[r,c] = (irisVerisColor[r,c] - minVerisColor_c)*2.0 /d_VerisColor- 1.0\n",
      "        irisVirginica_New[r,c]  = (irisVirginica[r,c]- minVir_c)*2.0/d_Vir - 1.0\n",
      "\n",
      "\n",
      "def SetupDataset(irisSetosa, irisVerisColor, irirsVirginica):\n",
      "    train_mats1 = [irisSetosa[10:50,:], irisVerisColor[10:50,:], irisVirginica[10:50,:]]\n",
      "    test_mats1  = [irisSetosa[0:10,:],  irisVerisColor[0:10,:], irisVirginica[0:10,:]]\n",
      "\n",
      "    train_mats2 = [np.concatenate((irisSetosa[0:10, :], irisSetosa[20:50,:]), axis = 0), \n",
      "                   np.concatenate((irisVerisColor[0:10,:], irisVerisColor[20:50,:]), axis = 0), \n",
      "                   np.concatenate((irisVirginica[0:10,:], irisVirginica[20:50,:]), axis = 0)]\n",
      "    test_mats2  = [irisSetosa[10:20,:], irisVerisColor[10:20,:], irisVirginica[10:20,:]]\n",
      "\n",
      "    train_mats3 = [np.concatenate((irisSetosa[0:20, :], irisSetosa[30:50,:]), axis = 0), \n",
      "                   np.concatenate((irisVerisColor[0:20,:], irisVerisColor[30:50,:]), axis = 0), \n",
      "                   np.concatenate((irisVirginica[0:20,:], irisVirginica[30:50,:]), axis = 0)]\n",
      "    test_mats3  = [irisSetosa[20:30,:], irisVerisColor[20:30,:], irisVirginica[20:30,:]]\n",
      "\n",
      "    train_mats4 = [np.concatenate((irisSetosa[0:30, :], irisSetosa[40:50,:]), axis = 0), \n",
      "                   np.concatenate((irisVerisColor[0:30,:], irisVerisColor[40:50,:]), axis = 0), \n",
      "                   np.concatenate((irisVirginica[0:30,:], irisVirginica[40:50,:]), axis = 0)]\n",
      "    test_mats4  = [irisSetosa[30:40,:], irisVerisColor[30:40,:], irisVirginica[30:40,:]]\n",
      "\n",
      "    train_mats5 = [irisSetosa[0:40,:], irisVerisColor[0:40,:], irisVirginica[0:40,:]]\n",
      "    test_mats5  = [irisSetosa[40:50,:], irisVerisColor[40:50,:],irisVirginica[40:50,:]]\n",
      "\n",
      "\n",
      "    train_mats_New = [train_mats1, train_mats2, train_mats3, train_mats4, train_mats5]\n",
      "    test_mats_New  = [test_mats1, test_mats2, test_mats3, test_mats4, test_mats5]\n",
      "    return train_mats_New, test_mats_New\n",
      "\n",
      "train_mats_New, test_mats_New = SetupDataset(irisSetosa_New, irisVerisColor_New, irisVirginica_New)\n",
      "\n",
      "h = 5\n",
      "question2(train_mats_New, test_mats_New, h)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Confusion matrix\n",
        "[10, 0, 0]\n",
        "[0, 10, 0]\n",
        "[0, 1, 9]\n",
        "----------------------------------\n",
        "[10, 0, 0]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0, 10, 0]\n",
        "[0, 1, 9]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----------------------------------\n",
        "[10, 0, 0]\n",
        "[0, 8, 2]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "[10, 0, 0]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0, 9, 1]\n",
        "[0, 1, 9]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----------------------------------\n",
        "[10, 0, 0]\n",
        "[0, 10, 0]\n",
        "[0, 0, 10]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15\n",
        "21\n",
        "9\n",
        "5\n",
        "Confusion matrix\n",
        "[9, 1, 0]\n",
        "[3, 7, 0]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0, 0, 10]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----------------------------------\n",
        "[7, 3, 0]\n",
        "[5, 5, 0]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "[6, 4, 0]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[5, 5, 0]\n",
        "[0, 0, 10]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----------------------------------\n",
        "[9, 1, 0]\n",
        "[6, 4, 0]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "[8, 2, 0]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[9, 1, 0]\n",
        "[0, 0, 10]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "array = np.array([8.1, 8.2 ,8.4, -1])\n",
      "maxValue = np.amax(array)\n",
      "print(maxValue)\n",
      "minValue = np.amin(array)\n",
      "print(minValue)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8.4\n",
        "-1.0\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = 3\n",
      "b = 2\n",
      "c = b/a\n",
      "print(c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.6666666666666666\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.array([1, 1])\n",
      "b = np.array([0, 0])\n",
      "norm = np.linalg.norm(a-b)\n",
      "print(norm)\n",
      "print(norm*norm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.41421356237\n",
        "2.0\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Question 3: classifying iris data using k-nearest neighbor algorithm\n",
      "def Compute_Distance_Two_Loops(X, X_train):\n",
      "    \"\"\"\n",
      "    compute the distance between test point in X and each training point in X_train\n",
      "    Input: \n",
      "    X - a numpy array has shape [NxD] - N - number of samples & D- dimesion of vector\n",
      "    X_train - a numpy array has shape [MxD] - M - number of training samples\n",
      "    Output:\n",
      "    dists - a numpy array that has shape of [NxM], \n",
      "    an element dists[i,j] - distance between i-th test point and j-th training point\n",
      "    \"\"\"\n",
      "    num_test = X.shape[0]\n",
      "    num_train = X_train.shape[0]\n",
      "    dists = np.zeros((num_test, num_train))\n",
      "    \n",
      "    for i in range(num_test):\n",
      "        for j in range(num_train):\n",
      "            dists[i,j] = np.linalg.norm(X_train[j,:]- X[i,:])\n",
      "    return dists\n",
      "\n",
      "def Compute_Distance_One_Loop(X, X_train):\n",
      "    \"\"\"\n",
      "    using broadcast to compute distance between test points and training samples\n",
      "    \"\"\"\n",
      "    num_test = X.shape[0]\n",
      "    num_train = X_train.shape[0]\n",
      "    dists = np.zeros((num_test, num_train))\n",
      "    for i in range(num_test):\n",
      "        dists[i, :] = np.sqrt(np.sum(np.square(X_train - X[i, :]), axis = 1))\n",
      "    \n",
      "    return dists\n",
      "\n",
      "def Compute_Distance_No_Loop(X, X_train):\n",
      "    \"\"\"\n",
      "    compute the distance between test point X and each training samples\n",
      "    \"\"\"\n",
      "    num_test = X.shape[0]  # N testing points\n",
      "    num_train = X_train.shape[0] # M training samples\n",
      "    dists = np.zeros([num_test, num_train])\n",
      "    \n",
      "    test_NxM = np.array([np.sum(np.square(X) , axis = 1)]*num_train).transpose()\n",
      "    #print(\"test shape: \",test_NxM.shape)\n",
      "    train_NxM = np.array([np.sum(np.square(X_train), axis = 1)]*num_test)\n",
      "    #print(\"train_shape: \", train_NxM.shape)\n",
      "    dists = np.sqrt(X.dot(X_train.transpose())*(-2) + test_NxM  + train_NxM)\n",
      "    \n",
      "    return dists\n",
      "\n",
      "def predict_labels_KNN(dists, y_train, k =1):\n",
      "    '''\n",
      "    given a dists matrix N*M between N test points and M training samples, predict label\n",
      "    for each test point\n",
      "    \n",
      "    Input:\n",
      "    dists - N*M matrix\n",
      "    Output:\n",
      "    y_predict - a vector of length num_test where y[i] is the predicted label for i-th test point\n",
      "    \n",
      "    '''\n",
      "    \n",
      "    num_test = dists.shape[0]\n",
      "    y_predict = np.zeros(num_test)\n",
      "    \n",
      "    for i in range(num_test):\n",
      "        # a list of length k storing the labels of k -nearest neighbors to the ith test point\n",
      "        closest_y = []\n",
      "        indexs = np.argsort(dists[i,:])\n",
      "        for w in range(0, k):\n",
      "            closest_y.append(y_train[indexs[w]])\n",
      "        \n",
      "        closest_y_int = [int(i) for i in closest_y]\n",
      "        count = []\n",
      "        labels = set(y_train)\n",
      "        for label_value in range(len(labels)):\n",
      "            count.append(0)\n",
      "        \n",
      "        \n",
      "        for j in range(k):\n",
      "            count[closest_y_int[j] - 1] += 1\n",
      "            \n",
      "        y_predict[i] = np.argmax(count) #note : return 0 - label type 1, return 1 - label type 2\n",
      "    \n",
      "    y_out = [int(i) for i in y_predict]\n",
      "    \n",
      "    return y_out\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test K-NN with iris data\n",
      "def classify_question_3(trainMats, testMats, num_loop = 2):\n",
      "    train = np.concatenate((trainMats[0],trainMats[1], trainMats[2]),axis = 0)\n",
      "    print(train.shape)\n",
      "    for i in range(3):\n",
      "        test = testMats[i]\n",
      "        c = [0, 0, 0]\n",
      "        #c[np.argmax(parray)] += 1\n",
      "        \n",
      "        \n",
      "        y_train = np.zeros(120)\n",
      "        y_train[0:40]  = 1\n",
      "        y_train[40:80] = 2\n",
      "        y_train[80:120]= 3\n",
      "        \n",
      "        #k-NN with two loops\n",
      "        if (num_loop == 2):\n",
      "            dists = Compute_Distance_Two_Loops(test, train)\n",
      "        #k-NN with one loops\n",
      "        elif (num_loop == 1):\n",
      "            dists = Compute_Distance_One_Loop(test, train)\n",
      "        #k-NN with no loop\n",
      "        else:\n",
      "            dists = Compute_Distance_No_Loop(test,train)\n",
      "            \n",
      "        \n",
      "        y_prec = predict_labels_KNN(dists, y_train, k =15)\n",
      "        for label in range(len(y_prec)):\n",
      "            c[y_prec[label]] += 1\n",
      "\n",
      "        \n",
      "        print(c)\n",
      "\n",
      "def question3(train, test, num_Loop = 2):\n",
      "    print(\"Confusion matrix\")\n",
      "    C1 = classify_question_3(train[0], test[0], num_Loop)\n",
      "    print(\"----------------------------------\")\n",
      "    C2 = classify_question_3(train[1], test[1], num_Loop)\n",
      "    print(\"----------------------------------\")\n",
      "    C3 = classify_question_3(train[2], test[2], num_Loop)\n",
      "    print(\"----------------------------------\")\n",
      "    C4 = classify_question_3(train[3], test[3], num_Loop)\n",
      "    print(\"----------------------------------\")\n",
      "    C5 = classify_question_3(train[4], test[4], num_Loop)\n",
      "\n",
      "question3(train_mats, test_mats, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Confusion matrix\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 9, 1]\n",
        "[0, 1, 9]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 10, 0]\n",
        "[0, 0, 10]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 8, 2]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 9, 1]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 10, 0]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0, 0, 10]\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "X = np.array(([1.0, 1.0, 2.0], [1.0, 1.0, -1.0]))\n",
      "print(np.sum(np.square(X), axis = 1))\n",
      "print(np.array([np.sum(np.square(X), axis = 1)]*10).transpose())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 6.  3.]\n",
        "[[ 6.  6.  6.  6.  6.  6.  6.  6.  6.  6.]\n",
        " [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.]]\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "closest_y = [4, 2, 3, 1, 2, 3, 1, 2, 4, 4,4]\n",
      "labels = set(closest_y)\n",
      "print(labels)\n",
      "\n",
      "count = []\n",
      "for label_value in range(len(labels)):\n",
      "    count.append(0)\n",
      "    \n",
      "print(count)\n",
      "\n",
      "for j in range(len(closest_y)):\n",
      "    count[closest_y[j]-1] += 1\n",
      "            \n",
      "    y_predict = np.argmax(count)\n",
      "print(y_predict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{1, 2, 3, 4}\n",
        "[0, 0, 0, 0]\n",
        "3\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def time_function(f, *args):\n",
      "    import time\n",
      "    tic = time.time()\n",
      "    f(*args)\n",
      "    toc = time.time()\n",
      "    return toc-tic\n",
      "\n",
      "time_2_loop = time_function(question3, train_mats, test_mats, 2)\n",
      "print(time_2_loop)\n",
      "\n",
      "time_1_loop = time_function(question3, train_mats, test_mats, 1)\n",
      "print(time_1_loop)\n",
      "\n",
      "time_no_loop = time_function(question3, train_mats, test_mats, 0)\n",
      "print(time_no_loop)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Confusion matrix\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 9, 1]\n",
        "[0, 1, 9]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 10, 0]\n",
        "[0, 0, 10]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 8, 2]\n",
        "[0, 0, 10]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 9, 1]\n",
        "[0, 0, 10]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 10, 0]\n",
        "[0, 0, 10]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.3502926826477051\n",
        "Confusion matrix\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 9, 1]\n",
        "[0, 1, 9]\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 10, 0]\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 8, 2]\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 9, 1]\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 10, 0]\n",
        "[0, 0, 10]\n",
        "0.019547700881958008\n",
        "Confusion matrix\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 9, 1]\n",
        "[0, 1, 9]\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 10, 0]\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 8, 2]\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 9, 1]\n",
        "[0, 0, 10]\n",
        "----------------------------------\n",
        "(120, 4)\n",
        "[10, 0, 0]\n",
        "[0, 10, 0]\n",
        "[0, 0, 10]\n",
        "0.011810779571533203\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}